
# Advanced Vehicle Classification for Enhanced Homeland Security

# Car Image Classifier with Fine-Tuned ResNet18

In line with **HTX's mission to harness cutting-edge technologies for safeguarding Singapore**, this project delivers a **computer vision solution** to accurately classify vehicle types from images. Designed for **Home Team departments** such as the **Singapore Police Force** and the **Immigration and Checkpoints Authority**, it enhances surveillance, traffic management, and security operations.

---

## Key Features

- **High-Precision Classification**: Fine-tuned **ResNet-18** model trained on the **Stanford Cars Dataset** to distinguish 196 car models with high accuracy.  
- **Real-Time API Integration**: FastAPI-based service enabling seamless integration for instantaneous vehicle identification.  
- **Scalable and Secure Deployment**: Docker containerization ensures easy deployment, scalability, and security across operational environments.

---

## Strategic Alignment

This project supports **HTX's commitment** to advancing science and technology within the **Home Team**, enhancing situational awareness and operational efficiency to safeguard Singapore’s safety and security.

---

## Table of Contents
1. [Project Overview](#project-overview)
2. [Dataset](#dataset)
3. [Directory Structure](#directory-structure)
4. [Setup and Installation](#setup-and-installation)
5. [Training the Model](#training-the-model)
6. [Running the API](#running-the-api)
7. [Results](#results)
8. [Acknowledgements](#acknowledgements)

---

## Dataset

The project uses the **Stanford Cars Dataset**, which contains 16,185 images of 196 car classes. 

Source: Kaggle - Stanford Cars Dataset
Contents:
Training Set: 8,144 images with annotations.
Testing Set: 8,041 images with annotations.
Metadata: Includes class names and bounding box coordinates for each image.
Classes: 196 distinct car models, ranging from sedans to SUVs, annotated with specific makes and models.
Image Resolution: High-resolution images, varying in size, with diverse backgrounds and lighting conditions.

- **Dataset Source (Images):** 
[Stanford Cars Dataset Images](https://www.kaggle.com/datasets/jessicali9530/stanford-cars-dataset?resource=download)
- **Dataset Source (Annotations):** [Stanford Cars Dataset Annotation] (https://www.kaggle.com/code/subhangaupadhaya/pytorch-stanfordcars-classification/input?select=cars_test_annos_withlabels+%281%29.mat)

```bash
data/
├── raw/
│   ├── standford-cars-dataset/       # Raw images (train/test)
│   ├── standford-cars-dataset-meta/  # Metadata (annotations)
├── processed/
│   ├── cropped_train/                # Cropped training images (generated by script)
│   └── cropped_test/                 # Cropped test images (generated by script)
```
## Directory Structure
```bash
project/
├── app/                                # API service code
│   ├── app.py                          # FastAPI application
│   ├── utils/                          # Utility functions
│   │   ├── data_loading.py             # Functions for loading and parsing data
│   │   ├── image_processing.py         # License plate detection and preprocessing
│   │   └── model_utils.py              # Model save/load utility
├── data/                               # Dataset folder (explained above)
├── mlruns/                             # MLflow experiment tracking logs
├── notebooks/                          # Jupyter Notebooks for model training
│   ├── train_model.ipynb               # Model training and evaluation
├── Dockerfile                          # Docker configuration
├── requirements.yaml                    # Python dependencies
├── README.md                           # This file
└── .gitignore                          # Ignored files
```

## Setup and Installation

1. Clone the repo
```bash
    git clone <insert github link>
```

2. Install conda environment

```bash
  conda env create -f environment.yml
  cd my-project
```

3. Check if Docker Is installed. Run the following command to check if Docker is installed. 

```bash
    docker --version
```
If Docker is installed, it will display the version number (e.g., Docker version 20.10.21, build 20fd1d6).

5. Verify Docker Daemon Is Running

```bash
    docker info
```
If the command fails, they need to start Docker. On macOS or Windows, this typically means opening the Docker Desktop application.


# Training the Model

Ensure the dataset is in the correct directory structure (see Dataset).
Run the Jupyter Notebook for training:
jupyter notebook notebooks/train_model.ipynb
Key steps in the notebook:
Data loading and preprocessing
Model fine-tuning with ResNet18
Experiment tracking with MLflow
Evaluation (confusion matrix, precision/recall)

# Running the API

1. Build and run the Docker container

```base
    docker build -t stanford-cars-api .
    docker run -p 8000:8000 stanford-cars-api
```

2. Open your browser and navigate to:

```base
    http://localhost:8000/docs
```
This opens the Swagger UI where you can interact with the API.
Use the /predict/ endpoint to upload an image for classification.

# Results
    
## Model and Dataset

